<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>重复囚徒困境策略主宰任何进化的对手(2012)</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">重复囚徒困境策略主宰任何进化的对手(2012)</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-05-17 02:52:04</div><div class="story_img_container"><img src="http://img.diglog.com/img/2020/5/c611b78914c545358d98bbbfa8be6654.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></div><div class="page_narrow text-break page_content"><p>两人重复的囚徒困境游戏是感官行为和进化行为的典范，特别是合作的出现。通常认为，不存在简单的最后通牒策略，即一个玩家可以单方面要求获得不公平的奖励份额。在这里，我们证明了这样的策略出人意料地存在。具体地说，知晓这些策略的玩家X可以(I)确定地设定她的对手Y的分数，而与他的策略或反应无关，或者(Ii)强制在她和他的分数之间建立敲诈勒索的线性关系。面对这样的玩家，进化型玩家最好的反应就是同意敲诈。只有对对手有心理理论的玩家才能做得更好，在这种情况下，重复囚徒困境是一个最后通牒游戏。</p><p>德克萨斯大学计算机科学系和生物科学学院，奥斯汀，德克萨斯州奥斯汀，邮编：78712；</p><p>ﬁ最先有三列M‘，省略了四列中的每一列。</p><p>图1.。(A)PD单打。玩家X(蓝色)和Y(红色)各自选择合作(C)或叛逃(D)各自的收益R、T、S或rP，如图所示(连同。</p><p>最常见的数值)。(B)IPD，其中相同的两个玩家任意玩多次；每个人都有基于ﬁNite记忆的策略。</p><p>以前的剧目。(C)两个Memory-1玩家的情况。每个玩家的策略是四个概率(合作)的向量，以四个结果为条件。</p><p>设置为(但为≥)0。在这种情况下，p2接近(但≤)1，p3接近。</p><p>P≤s Y≤R(而不是其他的)可以由X强制。也就是说，X可以设置</p><p>X试着设定她自己的分数。如果X试图设定她自己的分数怎么办？</p><p>1个−2个ϕ-χ−1？；1个−ϕ-2个χ塔1？；ϕ-1个χ塔4个？；0个；[15]。</p><p>0&lt；ϕ≤in4χta1？−1.X和Y的最好成绩分别为。</p><p>因为χ→∞是13/3。但是，在这个限制中，Y的分数始终是1，</p><p>因此，对他来说，没有合作的动机。X的贪婪是这样的。</p><p>导致ﬁ中非常长的“决斗”的策略)更有可能出现在。</p><p>对于他的行为，我们可以说Y对X有一种心理理论。</p><p>3显示了此指标的10个任意选项。在任何情况下，Y都不会</p><p>她的ZD策略，以便用一个ﬁctiousﬁtness land来欺骗Y-。</p><p>(从X的角度来看)到一种ﬁXed策略，而X的IMP-XED策略是针对这一策略的。</p><p>没有那么脆。因为X必须把她的决定建立在Y的基础上。</p><p>X和Y的响应之间存在竞争条件的可能性。</p><p>独特的心理理论，但只取决于Y归因于X的能力。</p><p>y在ipd游戏的骗局ﬁnes中是如此容易被击败，它是。</p><p>Y，X的得分完全相同，就好像Y打了一个特定的曲子。</p><p>图3.10个实例中X分数(蓝色)和Y分数(红色)的演变。</p><p>从健忘玩家X的角度看：如果X认为Y。</p><p>容量MαIαI ta 1 iFQ IαI？，αI ta 1∈fcc；cd；dc；dd g，其中q iαI是αi。</p><p>这里，符号i_j_α将被理解为“对于i的值，使得。</p><p>玩ﬁx策略Qαüh Q iαi i jα。因为X的ZD策略是。</p><p>独立于Y的任何ﬁx策略，我们已经证明，对于。</p><p>2.Roberts K(1985)卡特尔行为与逆向选择。工业经济33：401-413。</p><p>3.Axelrod R，Dion D(1988)合作的进一步发展。科学242：1385-1390。</p><p>5.Nowak MA(2006)关于合作演变的五条规则。科学314：1560-1563。</p><p>6.Kendall G，姚X，崇西(2007)20年过去了，重复的囚徒困境。</p><p>10.Hauert Ch，Schuster HG(1997)增加学生和学生人数的效果。</p><p>11.Premack DG，Woodruff G(1978)黑猩猩有心理理论吗？行为。</p><p>12.Saxe R，Baron-Cohen S编(2007)心理理论：社会神经特刊-。</p><p>..。最近，在完全监控的重复博弈中，发现了一类新的策略，称为零行列式(ZD)策略[6]。令人惊讶的是，ZD策略单方面地强制玩家的平均收益之间存在线性关系。..。</p><p>..。在标准重复博弈中，通过引入贴现因子δ�1[1]来考虑对未来收益的贴现。在Press和Dyson关于ZD策略的原始工作中，只研究了没有折扣(即δ=1)的情况[6]。经过他们的工作，ZD策略被扩展到δ&lt；1例[18，25，26]。..。</p><p>..。以下定义是ZD策略[6，27]概念的扩展，适用于多人多动作公共监控游戏。..。</p><p>零决定式(ZD)策略是最近发现的一类新的重复博弈策略，在进化博弈论中引起了广泛的关注。ZD策略单方面强制玩家的平均收益之间存在线性关系。虽然ZD策略的存在性和演化稳定性已经在简单博弈中得到了研究，但其数学性质还不是很清楚。例如，当一个以上的玩家使用ZD策略时会发生什么，这一点还没有弄清楚。在这篇文章中，我们提供了一个通用的框架来调查超过一个玩家在线性代数方面使用ZD策略的情况。首先，我们从理论上证明了ZD策略强制实施的平均收益的线性关系集总是有解的，这意味着不相容的线性关系是不可能的。其次，证明了线性支付关系在一定条件下是相互独立的。这些结果适用于具有公共监控的一般游戏，包括完美监控游戏。此外，我们还提供了一个两人博弈的简单例子，其中一个参与者可以同时实施两个线性关系，即同时控制她和她对手的平均收益。所有这些结果阐明了ZD策略的一般数学性质。</p><p>..。很少有方案达到全局最优，更不用说强迫对方合作实现最优计算的设计方案了。本文根据Press和Dyson[6]的模型，研究了大数据环境下合理的委托计算，以保证计算结果的正确性和可靠性。针对理性委托计算中计算方和合作方利益最大化的挑战，从委托方的角度出发，采用零决策策略方法，根据计算方的偏好和利益来调整计算方的利益。..。</p><p>..。在本文中，我们使用零决定策略来调整工人的期望收益，以激励其持久的合作。在这篇文章中，我们使用了零决定策略来调整工人的期望收益，以激励他的永久合作。零确定性策略是由Press和Dyson[6]在2012年提出的。ZD玩家可以通过强制两个预期收益之间的线性关系，单方面将对手的预期收益设定在一个固定值上。..。</p><p>..。最近，在[14]中，研究了零定策略从两人对策到多人对策的扩展。在[18]中，Rong et al.。调查了策略选择时间尺度的影响，发现如果一个人允许高回报的个人更长时间地持有他/她的成功策略，合作就会得到促进，这也是最初在[6]中提到的。..。</p><p>委托计算是解决云计算环境下任务分包和委托计算结果正确性和可靠性的重要途径。然而，云计算的动态性、复杂性和开放性给计算任务的安全性和可靠性带来了前所未有的风险。为了解决这一问题，提出了一种新的方法。首先将博弈论引入委托计算，给出了单客户多服务器理性委托计算博弈模型。其次，通过实施单客户端、单服务器理性委托计算协议和零决策策略，构建了基于委托计算的零决策策略方案，并分析了零决策策略纳什均衡存在的条件。然后，通过零决定论战略的迭代实施，参与方将积极合作。最后，性能分析结果表明，委托方可以通过零决定策略来规范计算方中的背叛者，以保障云计算中诚实人的利益。</p><p>..。在这项工作中，通过大规模的超级计算，我们证明了在确定性记忆中存在极少的友好竞争策略-没有未来折扣的迭代PD博弈的三种策略。与Press和Dyson(2012)中研究的策略不同；Hilbe等人。(2013aHilbe等人)。(，2014Hilbe等人)。(，2013b；Stewart和Plotkin(2013,2014))，我们的战略是确定性的战略，这使得它们都很容易作为一项公共政策实施，而不需要任何随机装置(Dror，1983)。特别是，我们关注其中一个友好的竞争对手，名为Capri，因为它可以用通俗易懂的语言(SEC)来描述。..。</p><p>..。我们尤其要强调记忆长度在理论和实验上的重要性，因为对记忆-1策略的研究已经引起了很多关注(Stewart和Plotkin，2013,2014；Akin，2016；Hilbe等人，2015；Baek和Kim，2008；Hilbe等人，2018b；Ichinose和Masuda，2018)。除了战略可能性的组合爆炸，人们可以争辩说，记忆一号策略，如果设计得当，可以单方面控制合作玩家的收益，即使合作玩家拥有更长的记忆力(Press and Dyson，2012)。研究还表明，m=1对于记忆更长的突变体的进化稳健性是足够的(Stewart和Plotkin，2013)。..。</p><p>直接互惠是我们社会生活中合作的重要机制之一。根据最近的理解，大多数直接互惠的经典战略可分为两类，“合作伙伴”或“竞争对手”。“合作伙伴”是实现相互合作的慷慨战略，而“竞争对手”从不让合作伙伴变得更富裕。他们有不同的工作条件：例如，合作伙伴在大量人口中表现良好，而竞争对手在面对面的比赛中表现良好。通过穷举的方法，我们证明了既是伙伴又是竞争对手的策略的存在性。其中，我们重点介绍了一种人类可理解的策略，名为“CAPRI&#39；CAPRI&39；”，它由五个简单的规则描述。我们的进化模拟表明，CAPRI在广泛的环境条件下表现出优异的性能。</p><p>..。在传统的PD博弈中，支付矩阵与每个代理的行动相关联</p><p>本文提出了一个统一的概率框架，允许在经典和量子博弈中对理性和非理性决策进行理论研究和模拟。理性选择理论是博弈论模型的基本组成部分，它假定决策者根据自己的偏好选择最佳行动。在本文中，我们将非理性定义为偏离理性选择。提出双稳态概率作为博弈中非理性决策建模的一种原则性和直截了当的方法。分析了经典和量子囚徒困境、Stag Hunt和鸡的双稳态变体，以评估非理性对代理效用和纳什均衡的影响。研究发现，三个经典双稳态博弈都存在最多三个纳什均衡，并且当代理人是理性的时，效用达到最大。所有三个量子双稳态博弈都存在多达三个纳什均衡，然而，效用随着代理非理性水平的提高而增加。</p><p>..。o cenário ilustrvo do diema do prisioneiróe composto de dois membros de Uma煤矸石刑事犯罪q s são presos e mantidos disados um do do tro e submetidos a um interrogatório，sem que haja qualquer tipo de Comunicaç˜Comunicação entre eles durante to do esse Processo。O clássico Dilema do Prisioneiro，apresentado atéagora，考量a apenas Uma Ocorrência para amamos os prisioneiros envolvidos，ma não e suffendente para model ar parmoadamente todas as Situitaç˜Situitaçóes possíveis；um algoritmo ainda mais flexível考量aria IteraçIteraç˜Iteraçáes。a Seçseç˜Seção 5.1.2.。</p><p>这项工作将解决音频信号固有的方面，以及伴随一些度量的性能评估标准，以及一些增强技术。它还将讨论人工神经网络，这是现在所知的深度学习的基础，也是生成性对抗性网络的起源，这是本工作的重点。最后，本文研究了两个问题：第一个目标是提高各种噪声场景下的语音质量和清晰度。在这里，我们使用了维纳滤波器，除了在非常嘈杂的情况下，它显示了最好的整体性能；对数-最小均方误差估计器，它的性能几乎和维纳一样好，但方差略小；以及SEGAN，它只在低信噪比情况下表现良好，但总体方差非常低。第二个问题寻求给声源定位算法提供性能增益，以便在极端噪声场景下(从−21 dB到24 dB)找到从无人机上的麦克风阵列检测到的遇险哭声的到达方向。研究了SEGAN和Log-MMSE，性能最好的是这两种序列的串行组合，它允许100%的准确率。</p><p>..。有可能这样的策略空间将产生比这里讨论的更多的纳什均衡或ESS(例如，参见参考文献)。60，61)。..。</p><p>领导可以有效地促进集团内部的合作，但俗话说“戴着皇冠的人头重脚轻”。很多争论仍然围绕着究竟是什么激励个人花费必要的努力来领导他们的组员。进化博弈论模型通过策略更新协议来描述个体的思维过程。其中最常见的是随机变异、个体学习、选择性模仿和近视优化。最近，我们引入了一种新的策略更新协议-前瞻-它考虑了未来的收益，以及组员如何对自己的策略做出反应。在这里，我们将我们的方法应用到一个新的2×2游戏中，其中一个玩家，一个领导者，通过检查和惩罚来确保另一个玩家，一个下属，产生集体利益。我们比较了纳什均衡、量子反应均衡、k级认知、虚拟游戏、强化学习、选择性收益偏向模仿和预见所预测的检验和生产水平。研究表明，只有先见之明、选择性模仿，才能有效地促进部属贡献和领导检查处分。选择性模仿在文化和社会进化中的作用得到了很好的评价。与我们之前的调查结果一致，远见是一条可行的合作替代途径。</p><p>..。另一套备受关注的IPD策略是零确定性策略(ZDS)[54]。通过强制收益之间的线性关系，ZDS可以确保他们的收益永远不会低于他们的对手。..。</p><p>重复的囚徒困境几十年来一直被用作行为互动的模型。从著名的针锋相对的表现，到零确定性策略的引入，再到神经网络等复杂结构的使用，多年来，文献一直在探索策略在游戏中的表现。文献学的研究成果</p><p>如果一个人将心理状态归结于自己和他人，那么他就有了心理理论。这种推论系统被恰当地视为一种理论，因为这样的状态不能直接观察到，而且该系统可以用来预测其他人的行为。至于黑猩猩可能推断出的精神状态，请考虑我们自己物种推断出的心理状态，例如，目的或意图，以及知识、信仰、思维、怀疑、猜测、假装、喜好等等。为了确定黑猩猩是否会推断出这种状态，我们向一只成年黑猩猩展示了一系列人类演员与各种问题作斗争的录像带场景。一些问题很简单，涉及到无法接触到的食物--垂直或水平够不到的香蕉，在盒子后面，等等-就像最初的科勒问题一样；另一些问题则更复杂，涉及到一个演员无法从锁着的笼子里挣脱出来，颤抖着，因为。</p><p>..</p></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.researchgate.net/publication/225054497_Iterated_Prisoners_Dilemma_Contains_Strategies_That_Dominate_Any_Evolutionary_Opponent">https://www.researchgate.net/publication/225054497_Iterated_Prisoners_Dilemma_Contains_Strategies_That_Dominate_Any_Evolutionary_Opponent</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/困境/">#困境</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/prisoners/">#prisoners</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/策略/">#策略</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/病毒/">#病毒</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>