<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>OpenPose：用于人体估计的实时多人关键点检测库</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">OpenPose：用于人体估计的实时多人关键点检测库</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-05-10 00:48:35</div><div class="story_img_container"><img src="http://img.diglog.com/img/2020/5/8431121b94c2180ad529d18f46ac699f.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></div><div class="page_narrow text-break page_content"><p>OpenPose代表了第一个在单个图像上联合检测人体、手、面部和脚部关键点(总共135个关键点)的实时多人系统。</p><p>它的作者是吉恩斯·伊达尔戈、哲·曹、托马斯·西蒙、魏世恩、朱汉斌和亚瑟·谢赫。目前，它由吉恩斯·伊达尔戈(Gines Hidalgo)和雅达夫·拉吉(Yaadhav Raaj)维护。此外，如果没有CMU全景工作室数据集，OpenPose是不可能实现的。我们也要感谢所有以任何方式帮助OpenPose的人。主要贡献者在doc/Contributors.md中列出。</p><p>作者Gines Hidalgo(左)和Hanbyul Joo(右)在CMU全景工作室前。</p><p>功能：2D实时多人关键点检测：15或18或25个关键点身体/脚部关键点估计。运行时间与检测到的人数不变。</p><p>输入：图像、视频、网络摄像头、Flir/Point Grey和IP摄像头。包含C++演示以添加您的自定义输入。</p><p>输出：基本图像+关键点显示/保存(PNG、JPG、AVI等)、关键点保存(JSON、XML、YML等)和/或关键点作为数组类。</p><p>2019年1月：改进的Python API发布！包括身体、面部、双手以及C++API的所有功能！</p><p>3个可用的姿势估计库之间的推断时间比较：OpenPose、Alpha-Ppose(快速Pytorch版本)和Mask R-CNN：</p><p>该分析针对每个算法使用相同的图像，批次大小为1。每次分析重复1000次，然后取平均值。这一切都是在NVIDIA 1080Ti和CUDA 8的系统上进行的。Megvii(Face++)和MSRA GitHub存储库被排除在外，因为它们只提供被裁剪的人的姿势估计结果。然而，它们遭遇了与Alpha-Ppose和Mask R-CNN相同的问题，它们的运行时间随着人数的增加而线性增长。大多数用户不需要OpenPose C++/Python API，只需使用OpenPose Demo即可：</p><p>OpenPose Demo：轻松处理图片/视频/摄像头，并显示/保存结果。参见doc/demo_overview.md。例如，使用以下命令在视频中运行OpenPose：</p><p>校准工具箱：轻松校准3-D OpenPose或任何其他立体视觉任务的相机。请参见doc/module/cal_module e.md。</p><p>OpenPose C++API：如果您想要读取特定的输入，和/或添加您的自定义后处理函数，和/或实现您自己的显示/保存，请查看示例/Tutorial_api_cpp/和doc/library_introtion.md上的C++API教程。您可以在Examples/USER_CODE/上创建自定义代码，并在编译整个OpenPose项目时使用CMake快速编译它。快速添加您的自定义代码：有关详细信息，请参阅Examples/USER_CODE/readme.md。</p><p>OpenPose Python API：类似于C++API，可以在Examples/Tutorial_API_python/上找到Python API的教程。</p><p>没有身体关键点检测的面部关键点检测：如果您想要加快检测速度(同时减少检测到的面数)，请检查doc/standalone_face_or_hand_keypoint_detector.md.中的opencv-face-Detector方法。</p><p>使用您自己的面/手检测器：可以将手和/或面关键点检测器与您自己的面或手检测器一起使用，而不是使用身体检测器。例如对于手可见但身体不可见的相机视图有用(OpenPose检测器将失败)。见doc/standalone_face_or_hand_keypoint_detector.md.。</p><p>在doc/Speed_up_openpose.md上查看OpenPose基准测试以及加快和/或降低OpenPose内存需求的一些提示。</p><p>有关脚部数据集的详细信息，请查看脚部数据集网站和新的OpenPose论文。</p><p>我们的图书馆是开源的，用于研究目的，我们希望不断完善它！所以请让我们知道如果..。</p><p>..。您会发现OpenPose似乎无法正常工作的视频或图像。请随时将它们发送到openposecu@gmail.com(仅限失败情况下发送电子邮件！)，我们将使用它们来提高算法的质量！</p><p>..。您向某个类或某个新的Worker子类添加了一些功能，我们可能会合并这些子类。</p><p>您只需在gihub上发表评论或提出拉取请求，我们会尽快回复！如果您使用该库制作很酷的演示或YouTube视频，请发送电子邮件给我们！</p><p>如果这些论文对你的研究有帮助，请在你的出版物中引用这些论文。OpenPose的大部分是基于[8765346]的。此外，手部和面部关键点检测器是[8765346]和[Simon等人]的组合。2017](面部检测器使用与手部检测器相同的程序进行训练)。</p><p>@文章{8765346，作者={Z.{CaO}和G.{伊达尔戈·马丁内斯}和T.{西蒙}和S.{魏}和Y.A.{谢赫}}，期刊={模式分析和机器智能学报}，标题={OpenPose：使用部分亲和场的实时多人二维姿势估计}，年份={2019年}}@InProcessing{simon2017Hand，作者={Tomas Simon和Hanbyul Joo和Iain Matthews and Y。年份={2017}}@正在进行{cao2017realtime，作者={曹哲和托马斯·西蒙以及魏世恩和亚瑟·谢赫}，书名={cvpr}，标题={使用部分亲和场的实时多人2D姿势估计}，年份={2017}}@正在进行{wei2016cpm，作者={Shih-en wei and Varun Ramakrishna and Takeo Kanade和Yaser Sheikh}，书名。</p><p>OpenPose可免费用于非商业用途，并可在这些条件下重新分发。有关详细信息，请参阅许可证。对商业许可证感兴趣吗？检查此Flintbox链接。对于商业查询，请使用Flintbox链接中的Contact部分，并将该消息的副本发送给Yaser Sheikh。</p></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://github.com/CMU-Perceptual-Computing-Lab/openpose">https://github.com/CMU-Perceptual-Computing-Lab/openpose</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/用于/">#用于</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/real/">#real</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/openpose/">#openpose</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/病毒/">#病毒</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>