<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>符号数学最终屈服于神经网络</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">符号数学最终屈服于神经网络</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-05-26 14:37:56</div><div class="story_img_container"><img src="http://img.diglog.com/img/2020/5/73cb20ff9fff6a5b8ff5254500f753ff.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></div><div class="page_narrow text-break page_content"><p>70多年前，处于人工智能研究前沿的研究人员引入了神经网络，将其作为一种革命性的方式来思考大脑是如何工作的。在人脑中，由数十亿个相互连接的神经元组成的网络能够理解感觉数据，使我们能够从经验中学习。人工神经网络还可以通过连接层过滤大量数据，按照他们自己学习的规则进行预测和识别模式。</p><p>到目前为止，人们将神经网络视为一种人工智能的灵丹妙药，能够解决可以被重申为模式识别问题的技术挑战。他们提供听起来自然的语言翻译。照片应用程序使用它们来识别和分类你收藏中的反复出现的面孔。由神经网络驱动的程序已经在围棋和国际象棋等游戏中击败了世界上最好的棋手。</p><p>然而，神经网络在一个明显的领域一直落后：解决困难的符号数学问题。这些课程包括微积分课程的特点，比如积分学或常微分方程。障碍来自数学本身的性质，这需要精确的解决方案。相反，神经网络倾向于在概率上出类拔萃。他们学习识别图案-西班牙语翻译听起来最好，或者你的脸是什么样子-并能产生新的图案。</p><p>去年年底，在巴黎Facebook人工智能研究小组工作的两名计算机科学家纪尧姆·兰普尔(Guillaume Lample)和弗朗索瓦·查顿(François Charton)的情况发生了变化。他们公布了用神经网络解决符号数学问题的首个成功方法。他们的方法不涉及数字运算或数值近似。取而代之的是，他们发挥了神经网络的优势，根据一个实际上已经解决的问题-语言翻译-重新构造了数学问题。</p><p>“我们的专业都是数学和统计学，”研究人工智能在数学中的应用的查顿说。“数学是我们最初的语言。”</p><p>因此，兰普尔和查顿的程序可以产生复杂积分和微分方程的精确解-包括一些内置了显式解题规则的流行数学软件包。</p><p>新程序利用了神经网络的主要优势之一：它们开发了自己的隐含规则。因此，“规则和例外之间没有区别，”斯坦福大学(Stanford University)心理学家杰伊·麦克莱兰(Jay McClelland)说，他使用神经网络对人们学习数学的方式进行建模。在实践中，这意味着程序不会在最难的积分上跌跌撞撞。从理论上讲，这种方法可以推导出非传统的“规则”，可以在人或机器目前无法解决的问题上取得进展-数学问题，比如发现新的证据，或者理解神经网络本身的性质。</p><p>当然，这并不是说这件事还没有发生。但很明显，该团队已经回答了这个几十年来的问题-人工智能能做符号数学吗？-是肯定的。他说：“他们的模式已经确立。这些算法都是成熟的。他们巧妙地假设了这个问题，“人工智能研究集团OpenAI的联合创始人沃伊切赫·扎伦巴(Wojciech Zaremba)说。</p><p>麦克莱兰说：“他们确实成功地提出了神经网络，可以解决遵守规则的机器系统所不能解决的问题。”“这非常令人兴奋。”</p><p>计算机一向擅长处理数字。计算机代数系统将数十或数百种算法与预设指令相结合。它们通常是严格的规则追随者，旨在执行特定操作，但无法容纳异常。对于许多符号问题，它们产生的数值解足够接近工程和物理应用。</p><p>神经网络是不同的。他们没有固定的规则。取而代之的是，他们在大数据集上进行训练-越大越好-并使用统计数据做出非常好的近似。在这个过程中，他们学习什么能产生最好的结果。语言翻译程序特别出色：它们不是逐字翻译，而是在整个文本的上下文中翻译短语。Facebook的研究人员认为这是解决符号数学问题的优势，而不是障碍。它给了程序一种解决问题的自由。</p><p>这种自由对于某些开放式问题特别有用，比如整合。数学家中有一句老话：“差异化是力学，积分是艺术。”这意味着为了求出函数的导数，你只需遵循一些定义明确的步骤。但是要找到一个积分，通常需要一些其他的东西，一些更接近直觉的东西，而不是计算。</p><p>脸书小组怀疑这种直觉可以用模式识别来近似。“积分是数学中最像模式识别的问题之一，”查顿说。因此，即使神经网络可能不理解函数的作用或变量的含义，但它们确实发展了一种本能。神经网络开始感觉到什么是有效的，即使不知道为什么。</p><p>例如，一位数学家被要求对$LaTeX yy^{\Prime}\Left(y^{2}+1\right)^{-1/2}$}这样的表达式进行积分，他会直观地怀疑基元-即被微分以产生积分的表达式-包含看起来像y²x+1的平方根的东西。</p><p>为了让神经网络像数学家一样处理符号，查顿和兰普尔首先将数学表达式翻译成更有用的形式。他们最终将它们重新解释为树-一种在精神上类似于图表句子的形式。加法、减法、乘法和除法等数学运算符成为树上的连接点。像升幂或三角函数这样的运算也是如此。参数(变量和数字)变成了叶子。除了极少数例外，树结构捕获了操作可以嵌套在较长表达式中的方式。</p><p>兰普尔说：“当我们看到一个大函数时，我们可以看到它是由较小的函数组成的，并且对解决方案可以是什么有一些直觉。”“我们认为这个模型试图从符号中找到解决方案的线索。”他说，这个过程与人们解决积分的方式类似，实际上所有的数学问题都是通过将它们归结为他们以前解决过的可识别的子问题来解决的。</p><p>在提出这一架构后，研究人员使用一组初等函数生成了几个训练数据集，总计约2亿个(树形)方程和解。然后，他们将这些数据“输入”到神经网络，这样它就可以了解这些问题的解决方案是什么。</p><p>训练结束后，是时候看看网能做些什么了。计算机科学家对它进行了5000个方程式的测试，这次没有答案。(这些测试问题都没有被归类为“无法解决”。)。神经网络以优异的成绩通过了测试：它成功地获得了绝大多数问题的正确解决方案--精确度和全面性。它特别擅长集成，解决了几乎100%的测试问题，但在常微分方程方面略显逊色。</p><p>对于几乎所有的问题，程序只用了不到1秒的时间就生成了正确的解决方案。在积分问题上，在速度和精度上均优于流行软件包MATHEMICA和Matlab中的一些求解器。Facebook团队报告说，神经网络为这些商业解决方案中的任何一个都无法解决的问题提供了解决方案。</p><p>尽管有了这些结果，数学家罗杰·格蒙森(Roger Germundsson)对这种直接比较提出了异议。格蒙森是制造数学软件的Wolfram公司研发部门的负责人。Facebook的研究人员将他们的方法与数学软件的几个功能--积分的“积分”和微分方程的“DSolve”--进行了比较，但数学软件的用户可以使用成百上千个其他的求解工具。</p><p>Germundsson还指出，尽管训练数据集的规模巨大，但它只包括具有一个变量的方程，并且只包括那些基于初等函数的方程。“这只是一小部分可能的表达，”他说。神经网络没有在物理和金融中经常使用的更混乱的函数上进行测试，比如误差函数或贝塞尔函数。(Facebook小组表示，在未来的版本中，它可能会进行非常简单的修改。)。</p><p>加州大学圣巴巴拉分校(University of California，Santa Barbara)数学家弗雷德里克·吉布(Frédéric Gibou)研究过使用神经网络解决偏微分方程的方法，他并不相信Facebook小组的神经网络是万无一失的。“你需要有信心，它会一直起作用，而不仅仅是在某些选定的问题上，”他说，“但这里的情况并非如此。”其他批评人士指出，Facebook团队的神经网络并不真正理解数学；它更多的是一种特殊的猜测。</p><p>尽管如此，他们一致认为新的方法将被证明是有用的。Germundsson和Gibou相信神经网络将在下一代符号数学解算器的谈判桌上占有一席之地-它将只是一张大桌子。“我认为这将是众多工具中的一个，”Germundsson说。</p><p>除了解决符号数学这一具体问题外，Facebook小组的工作也是这种方法原理和力量的令人鼓舞的证明。剑桥大学数学家安德斯·汉森(Anders Hansen)说：“如果这些技术能让数学家解决人们以前解决不了的问题，他们总体上会印象非常深刻。”</p><p>神经网络的另一个可能的探索方向是开发自动定理生成器。兰普尔说，数学家们正在越来越多地研究如何使用人工智能来生成新的定理和证明，尽管“最先进的技术还没有取得很大的进展”。“这是我们正在考虑的问题。”</p><p>查顿描述了至少两种他们的方法可以推动人工智能定理发现者向前发展。首先，它可以充当一种数学家的助手，通过识别已知猜想中的模式来帮助解决现有的问题。其次，机器可能会生成数学家遗漏的潜在可证明结果的列表。“我们相信，如果你能做整合，你应该能做证明，”他说。</p><p>为证据提供帮助最终可能是杀手级应用程序，甚至超出了Facebook团队所描述的范围。证明定理的一种常见方法是拿出一个反例来证明它不成立。有一天，这类神经网络可能会独一无二地适合这项任务：找到一个意外的扳手扔进机器里。</p><p>这种方法显示出希望的另一个悬而未决的问题是神经网络最令人不安的方面之一：没有人真正理解它们是如何工作的。训练比特从一端进入，预测比特从另一端出来，但在这两者之间发生了什么-使神经网络成为如此好的猜测者的确切过程-仍然是一个关键的悬而未决的问题。</p><p>另一方面，符号数学显然不那么神秘。“我们知道数学是如何运作的，”查顿说。“通过使用特定的数学问题作为测试，看看机器在哪里成功，在哪里失败，我们就可以了解神经网络是如何工作的。”</p><p>很快，他和兰普尔计划将数学表达式输入他们的网络，并追踪程序对表达式的微小变化的反应方式。映射输入触发器的变化在输出中的变化可能有助于揭示神经网络是如何运行的。</p><p>Zaremba认为，这种理解是教授神经网络进行推理并真正理解他们回答的问题的潜在一步。“在数学中，很容易移动指针，看看(神经网络)在表情变得不同时工作得有多好。我们可能会真正了解其中的道理，而不仅仅是答案，“他说。“结果将是相当有力的。”</p></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.quantamagazine.org/symbolic-mathematics-finally-yields-to-neural-networks-20200520/">https://www.quantamagazine.org/symbolic-mathematics-finally-yields-to-neural-networks-20200520/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/神经网络/">#神经网络</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/符号/">#符号</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/app/">#app</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/病毒/">#病毒</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/冠状病毒/">#冠状病毒</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>